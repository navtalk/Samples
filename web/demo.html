<!DOCTYPE html>
<html lang="zh">

<head>
    <style>
        /* Base reset and global styles */
        body {
            margin: 0;
            padding: 0;
            font-family: 'Arial', sans-serif;
            background-color: #f5f5f7;
            color: #333;
            height: 100vh;
            overflow: hidden;
        }

        /* Main container style */
        .real-time-container {
            display: flex;
            flex-direction: column;
            height: 100vh;
            position: relative;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        }

        /* Header button group */
        .ah-agent-header {
            display: flex;
            justify-content: flex-end;
        }

        .ah-btn-group {
            display: flex;
            gap: 10px;
        }

        .ah-btn {
            background: rgba(255, 255, 255, 0.2);
            border: none;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.3s ease;
            backdrop-filter: blur(5px);
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .ah-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 8px rgba(0, 0, 0, 0.15);
        }

        .ah-icon {
            transition: all 0.3s ease;
        }

        /* Character container */
        .ah-character-box {
            position: relative;
            width: 100%;
            height: 60vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .ah-character-avatar {
            border-radius: 20px;
            width: 80%;
            height: 80%;
            box-shadow: 0 20px 30px rgba(0, 0, 0, 0.2);
            overflow: hidden;
            background: #fff;
        }

        /* Character background */
        .ah-character-bg {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
            filter: blur(8px);
            opacity: 0.7;
        }

        /* Call button */
        .btn-character-call {
            position: fixed;
            bottom: 30px;
            right: 30px;
            width: 60px;
            height: 60px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            box-shadow: 0 10px 20px rgba(118, 75, 162, 0.3);
            z-index: 10;
        }

        .btn-character-call:hover {
            transform: scale(1.1);
            box-shadow: 0 15px 25px rgba(118, 75, 162, 0.4);
        }

        /* Active state */
        .btn-character-call.active {
            background: linear-gradient(135deg, #ff5e62 0%, #ff9966 100%);
        }

        /* Chat container */
        .ah-character-chat {
            position: fixed;
            bottom: 100px;
            left: 20px;
            right: 20px;
            max-height: 30vh;
            overflow-y: auto;
            padding: 15px;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        .character-chat-item {
            max-width: 70%;
            padding: 12px 18px;
            border-radius: 18px;
            font-size: 16px;
            line-height: 1.4;
            animation: fadeIn 0.3s ease-out;
        }

        .item-user {
            align-self: flex-end;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-bottom-right-radius: 4px;
        }

        .item-character {
            align-self: flex-start;
            background: white;
            color: #333;
            border-bottom-left-radius: 4px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        /* Scrollbar style */
        .ah-character-chat::-webkit-scrollbar {
            width: 6px;
        }

        .ah-character-chat::-webkit-scrollbar-track {
            background: rgba(0, 0, 0, 0.05);
            border-radius: 10px;
        }

        .ah-character-chat::-webkit-scrollbar-thumb {
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
        }

        
        /* Chat container */
        .item .item-content {
        padding: 12px 18px;
        border-radius: 18px;
        font-size: 16px;
        line-height: 1.4;
        animation: fadeIn 0.3s ease-out;
        margin-bottom: 15px;
        }

        .item {
        display: flex;
        }

        .item.item-left {
        justify-content: start;
        }

        .item.item-left .item-content {
        background: white;
        color: #333;
        border-bottom-left-radius: 4px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .item.item-right {
        justify-content: end;
        }

        .item.item-right .item-content {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-bottom-right-radius: 4px;
        }


        /* Animation definition */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Hover effect for video element */
        #character-avatar-video:hover {
            transform: translate(-50%, -50%) scale(1.02);
            transition: transform 0.3s ease;
        }

        /* Responsive adjustments */
        @media (max-width: 768px) {
            .ah-character-avatar {
                width: 90%;
                height: 70%;
            }

            .ah-character-chat {
                bottom: 80px;
                max-height: 25vh;
            }

            .btn-character-call {
                width: 50px;
                height: 50px;
                bottom: 20px;
                right: 20px;
            }
        }

        /* Dark mode */
        @media (prefers-color-scheme: dark) {
            body {
                background-color: #121212;
                color: #e0e0e0;
            }

            .ah-character-avatar {
                background: #1e1e1e;
            }

            .item-character {
                background: #2d2d2d;
                color: #e0e0e0;
            }

            .ah-btn {
                background: rgba(30, 30, 30, 0.5);
            }
        }

        /* Modify container height to 100% */
        .ah-character-box {
            height: 100vw;
            /* Subtract header height */
            width: 100vw;
        }

        /* Adjust video container style */
        .ah-character-avatar {
            width: 100% !important;
            height: 100% !important;
            border-radius: 0 !important;
            /* Remove border radius */
            box-shadow: none !important;
        }

        /* Fullscreen positioning for video element */
        #character-avatar-video {
            position: fixed !important;
            top: 0 !important;
            left: 0 !important;
            width: 100% !important;
            height: 100% !important;
            transform: none !important;
            z-index: 1;
        }

        /* Adjust background element */
        .ah-character-bg {
            display: none;
            /* Hide background image */
        }

        /* Adjust z-index of other elements */
        .btn-character-call {
            z-index: 9999;
        }

        .ah-character-chat {
            z-index: 999;
            bottom: 80px;
        }
    </style>

</head>

<body>

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<div class="real-time-container">
    <div class="ah-agent-header">
        <div class="ah-btn-group"></div>
    </div>

    <!-- character container -->
    <div class="ah-character-box">
        <div class="ah-character-avatar" style="position: relative; overflow: hidden; width: 100%; height: 100%;">
            <!-- Static image displayed by default -->
            <img id="character-static-image" src="https://easyaistorageaccount.blob.core.windows.net/easyai/man2.png"
                 style="position: absolute; top: 50%; left: 50%; width: 100%; height: 100%; object-fit: cover; transform: translate(-50%, -50%);">

            <!-- Video playback element (initially hidden) -->
            <video id="character-avatar-video"
                   style="position: absolute; top: 50%; left: 50%; width: 100%; height: 100%; object-fit: cover; transform: translate(-50%, -50%); display: none;"></video>
        </div>
    </div>

    <div class="ah-character-bg">
        <img style="width: 100%;height: 100%;object-fit: cover;"
             src="https://gd-hbimg.huaban.com/67869c1b642e1accb9378fb4af28a6f5729bd35530722-xfzjYw_fw1200" alt="">
    </div>

    <!-- Call button -->
    <button class="ah-btn ah-btn-icon btn-character-call" id="btnRealtime">
        <svg class="ah-icon" width="22" height="22" viewBox="0 0 22 22" fill="#fff"
             xmlns="http://www.w3.org/2000/svg">
            <path
                    d="M20.0001 15.58C17.0001 13.176 16.1281 14.378 14.8186 15.689C13.8371 16.672 11.4371 14.651 9.41862 12.575C7.34612 10.4995 5.32862 8.04101 6.31012 7.16701C7.67362 5.80201 8.81912 4.98201 6.41912 1.97751C4.01912 -1.02649 2.38262 1.26751 1.07412 2.57851C-0.453385 4.10851 0.964616 9.78901 6.58262 15.4155C12.2006 20.9875 17.8731 22.4625 19.4006 20.933C20.7096 19.622 23.0551 17.983 20.0006 15.5795L20.0001 15.58Z" />
        </svg>
    </button>

    <!-- Chat content -->
    <div class="ah-character-chat" :hidden="false">

                <div class="scroller"></div>

        <div class="character-chat-item item-user" style="display: none;">
            
        </div>
        <div class="character-chat-item item-character" style="display: none;">
           
        </div>

    </div>
</div>
</body>


<script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.26.0/prism.js"></script>


<script>
    // Global variable for connection state
    let peerConnectionA = null;
    let resultSocket = null;
    // Global state management
    let pc = null;
    let currentTracks = [];

    let baseUrl = "transfer.navtalk.ai"

    let configuration = { iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] };

    license = "sk_navtalk_gJPEiHXxspVQ7HQrjjgqPEQUyWsFf4DC"
    // Digital human agent, real-time voice conversation button
    async function initDigtalHumanRealtimeButton() {
        let realtimeChatHistory = await getFromChromeStorage("realtimeChatHistory");

        async function getFromChromeStorage(key) {
            return new Promise((resolve, reject) => {
                // Use localStorage in normal web pages
                const value = localStorage.getItem(key);
                resolve(value !== null ? value : null);
            });
        }

        realtimeChatHistory = JSON.parse(realtimeChatHistory);

        // Render chat history
        // renderRealtimeChatHistory();

        const realtimeButton = document.getElementById('btnRealtime');
        const conversationBg = document.querySelector('.conversation-bg'); // Select the entire div containing the background image

        let socket;
        let audioContext;
        let audioProcessor;
        let audioStream;
        let currentAudioSource = null; // Currently playing audio source

        // Get the stored digitalHumanLogId of the currently active character
        let activeCharacterLogId = await getFromChromeStorage("digitalHumanLogId");
        // const activeCharacter = realtimeChatHistory.find(character => character.digitalHumanLogId == activeCharacterLogId);

        // Loading animation
        let loading = document.querySelector('.ah-chat-loading');
        let aiMessageElement;
        // Define a variable to store accumulated transcript content
        let accumulatedTranscript = '';

        let audioQueue = []; // Used to store audio chunks
        let isPlaying = false; // Flag to indicate whether audio is currently playing
        // Use a Map to store the span element corresponding to each response_id
        let responseSpans = new Map();

        let playVideo = false;
        // Define a buffer object to accumulate incomplete Markdown content
        let markdownBuffer = new Map();

        realtimeButton.addEventListener('click', async function () {
            const staticImage = document.getElementById('character-static-image');
            const videoElement = document.getElementById('character-avatar-video');

            if (realtimeButton.classList.contains('active')) {
                // Stop state
                realtimeButton.classList.remove('active');
                stopRecording();

                if (conversationBg) {
                    conversationBg.style.display = 'none';
                }

                // Show static image and hide video
                staticImage.style.display = 'block';
                videoElement.style.display = 'none';

                // Pause video playback
                videoElement.pause();

                audioQueue = []; // Clear audio queue
                isPlaying = false; // Mark not playing

                // Optional: hide chat content
                document.querySelectorAll('.character-chat-item').forEach(item => {
                    item.style.display = 'none';
                });

            } else {
                // Start state
                realtimeButton.classList.add('active');
                startWebSocket();

                if (conversationBg) {
                    conversationBg.style.display = 'block';
                }

                // Hide static image and show video
                staticImage.style.display = 'none';
                videoElement.style.display = 'block';

                // Start video playback (make sure video source is set)
                videoElement.play().catch(e => console.error("Video playback failed:", e));

                // Show chat content
                document.querySelectorAll('.character-chat-item').forEach(item => {
                    item.style.display = 'block';
                });

                // Original GIF animation logic (commented)
                // if (conversationAnimation) {
                //     conversationAnimation.src = MyExtension.Utils.getChromeRuntimeURL('images/img-real-time.gif');
                // }
            }
        });

        // Clear the websocket on the front end
        async function cleanupResources() {
            try {
                console.log('Starting cleanup');

                if (pc) {
                    console.log('Closing PeerConnection');
                    pc.removeEventListener('icecandidate', on_icecandidate);
                    pc.removeEventListener('connectionstatechange', on_connectionstatechange);
                    pc.removeEventListener('iceconnectionstatechange', iceconnectionstatechange);
                    pc.removeEventListener('signalingstatechange', signalingstatechange);

                    if (pc.connectionState !== 'closed') {
                        await pc.close();
                        console.log('PeerConnection closed');
                    }
                    pc = null;
                }

                if (peerConnectionA) {
                    console.log('Closing peerConnectionA');
                    peerConnectionA.onicecandidate = null;
                    peerConnectionA.close();
                    peerConnectionA = null;  // Ensure it's completely reset
                }

                currentTracks.forEach(track => {
                    if (track.stop) track.stop();
                    if (track.dispatchEvent) {
                        track.dispatchEvent(new Event('ended'));
                    }
                });
                currentTracks = [];
                console.log('Tracks cleaned up');

                const remoteVideo = document.getElementById('character-avatar-video');
                if (remoteVideo) {
                    remoteVideo.srcObject = null;
                    remoteVideo.removeAttribute('src');
                    remoteVideo.load();
                }

                await new Promise(resolve => setTimeout(resolve, 100));
                console.log('Cleanup complete');
            } catch (err) {
                console.error('Resource cleanup error:', err);
            }
        }

        async function startWebSocket() {
            websocketUrl = "wss://"+baseUrl+"/api/realtime-api";
            // Retrieve license information from Chrome storage
            const websocketUrlWithParams = `${websocketUrl}?license=${encodeURIComponent(license)}&characterName=man2`;

            // Initialize the WebSocket connection
            socket = new WebSocket(websocketUrlWithParams);
            socket.binaryType = 'arraybuffer';

            // Listen for WebSocket messages
            socket.onmessage = (event) => {
                if (typeof event.data === 'string') {
                    try {
                        // Parse and handle non-binary messages
                        const data = JSON.parse(event.data);
                        // console.log("data:"+JSON.stringify(data))
                        handleReceivedMessage(data);
                    } catch (e) {
                        console.error("Failed to parse JSON message:", e);
                    }
                } else if (event.data instanceof ArrayBuffer) {
                    // Handle binary messages
                    const arrayBuffer = event.data;
                    handleReceivedBinaryMessage(arrayBuffer);
                } else {
                    console.warn("Unknown WebSocket message type");
                }
            };

            // Triggered when the WebSocket connection is successfully opened
            socket.onopen = function () {
                console.log("WebSocket connection established");
            };

            // Handle WebSocket errors
            socket.onerror = function (error) {
                console.error("WebSocket error: ", error);
            };

            // Triggered when the WebSocket connection is closed
            socket.onclose = async function (event) {
                // Show an error message if points are insufficient
                if (event.reason === 'Insufficient points') {
                    showErrorTip("You need more points to complete this action.");
                }
                console.log("WebSocket connection closed", event.code, event.reason);
                // Clean up old connection
                await cleanupResources();

                stopRecording();

                // Update the points information

                // Clear the span record elements
                responseSpans = new Map();

            };


            // WebSocket for receiving video results
            let remoteVideoA = document.getElementById('character-avatar-video');

            let targetSessionId = "123";
            console.log("Start connecting " + (new Date()).toLocaleTimeString())
            resultSocket = new WebSocket('wss://'+baseUrl+'/api/webrtc?userId=' + license);  // Replace with your WebSocket server address

            let localStream;

            resultSocket.onopen = () => {
                console.log("WebSocketResult connection established.");
                console.log("Connection successful " + (new Date()).toLocaleTimeString())
                const message = { type: 'create', targetSessionId: targetSessionId };
                resultSocket.send(JSON.stringify(message));
            };

            resultSocket.onmessage = (event) => {
                console.log("Received message:", event.data);
                const message = JSON.parse(event.data);
                console.log("Received message:", message.type);
                console.log("Received message:", message);
                if (message.type === 'offer') {
                    handleOffer(message);
                } else if (message.type === 'answer') {
                    handleAnswer(message);
                } else if (message.type === 'iceCandidate') {
                    handleIceCandidate(message);
                }
            };

            resultSocket.onerror = (error) => {
                // Clean up old connection
                cleanupResources();
                console.error("WebSocket error:", error);
            };

            resultSocket.onclose = (event) => {
                console.log("WebSocket connection closed:");
                console.log("  code:", event);
                console.log("  code:", event.code);
                console.log("  reason:", event.reason);
                console.log("  wasClean:", event.wasClean);
                console.log("  readyState:", resultSocket.readyState);
            };

            function handleOffer(message) {
                console.log("handleOffer")
                const targetId = message.targetSessionId;
                const offer = new RTCSessionDescription(message.sdp);
                peerConnectionA = new RTCPeerConnection(configuration);
                console.log("peerConnectionA", JSON.stringify(peerConnectionA))

                peerConnectionA.setRemoteDescription(offer)
                    .then(() => peerConnectionA.createAnswer())
                    .then(answer => peerConnectionA.setLocalDescription(answer))
                    .then(() => {
                        const responseMessage = {
                            type: 'answer',
                            targetSessionId: targetId,
                            sdp: peerConnectionA.localDescription
                        };
                        resultSocket.send(JSON.stringify(responseMessage));
                    })
                    .catch(err => console.error('Error handling offer:', err));

                // Add ICE state monitoring
                peerConnectionA.oniceconnectionstatechange = () => {
                    console.log('ICE connection state:', peerConnectionA.iceConnectionState);
                    if (peerConnectionA.iceConnectionState === 'connected') {
                        console.log('WebRTC connection fully established!');
                    } else if (peerConnectionA.iceConnectionState === 'failed') {
                        console.log('ICE connection failed, attempting reconnection...');
                        // You can add reconnection logic here
                    }
                };

                peerConnectionA.ontrack = (event) => {
                    console.log("ontrack")
                    console.log(event)
                    remoteVideoA.srcObject = event.streams[0]; // Show remote video
                    setTimeout(() => {
                        remoteVideoA.play()
                    }, 1000)
                };

                // Logs when handling ICE Candidate
                peerConnectionA.onicecandidate = (event) => {
                    console.log('onicecandidate:', event.candidate ? 'new candidate' : 'gathering complete');
                    if (event.candidate) {
                        const message = {
                            type: 'iceCandidate',
                            targetSessionId: targetSessionId,
                            candidate: event.candidate
                        };
                        resultSocket.send(JSON.stringify(message));
                    }
                };
            }

            // Function to handle Answer messages
            function handleAnswer(message) {
                const targetSessionId = message.targetSessionId;
                const map_item = events_maps.get(targetSessionId);
                if (!map_item) return;

                pc = map_item.peerConnection;
                const answer = new RTCSessionDescription(message.sdp);

                if (pc.signalingState === 'stable') {
                    console.warn('Triggering renegotiation: State is stable');
                    pc.restartIce(); // Force refresh ICE candidates
                    recreateOffer(pc, targetSessionId, map_item.socket); // Call renegotiation function
                } else if (pc.signalingState === 'have-local-offer') {
                    pc.setRemoteDescription(answer)
                        .catch(err => console.error('Failed to handle Answer:', err));
                }
            }

            // Function to recreate Offer
            async function recreateOffer(pc, targetSessionId, socket) {
                try {
                    // Create a new Offer
                    const offer = await pc.createOffer({
                        offerToReceiveAudio: true,
                        offerToReceiveVideo: true
                    });
                    await pc.setLocalDescription(offer);

                    // Send the new Offer to the peer
                    socket.send(JSON.stringify({
                        type: 'offer',
                        targetSessionId: targetSessionId,
                        sdp: pc.localDescription
                    }));
                } catch (err) {
                    console.error('Failed to recreate Offer:', err);
                }
            }

            function handleIceCandidate(message) {
                const candidate = new RTCIceCandidate(message.candidate);
                console.log(candidate)
                peerConnectionA.addIceCandidate(candidate)
                    .catch(err => console.error('Error adding ICE candidate:', err));
            }
        }



        function showErrorTip(message) {
            const realtimeButton = document.getElementById('btnRealtime');
            if (realtimeButton.classList.contains('active')) {
                realtimeButton.click();
            }
            const errorTip = document.getElementById("errorTipRealtime");
            errorTip.textContent = message;
            errorTip.style.display = "block";
            errorTip.style.opacity = "1";
            errorTip.style.visibility = "visible";
            // Automatically hide error message after 3 seconds
            setTimeout(() => {
                errorTip.style.opacity = "0";
                errorTip.style.visibility = "hidden";
                setTimeout(() => {
                    errorTip.style.display = "none";
                }, 500);
            }, 3000);
        }

        async function sendSessionUpdate() {
            const history = localStorage.getItem("realtimeChatHistory");
            const conversationHistory = history ? JSON.parse(history) : [];

            let userLanguage = await getFromChromeStorage("userLanguage");

            let activeCharacterLogId = await getFromChromeStorage("digitalHumanLogId");
            let realtimeChatHistory = await getFromChromeStorage("realtimeChatHistory");
            realtimeChatHistory = JSON.parse(realtimeChatHistory);

            // Session configuration
            let sessionConfig = {
                type: "session.update",
                session: {
                    instructions: "chat",
                    turn_detection: {
                        type: "server_vad",
                        threshold: 0.5,
                        prefix_padding_ms: 300,
                        silence_duration_ms: 500
                    },
                    voice: "ash",
                    temperature: 1,
                    max_response_output_tokens: 4096,
                    modalities: ["text", "audio"],
                    input_audio_format: "pcm16",
                    output_audio_format: "pcm16",
                    input_audio_transcription: {
                        model: "whisper-1"
                    },
                    tools: [
                        {
                            type: "function",
                            name: "function_call_judge",
                            description: "Are there any function calls or tasks beyond your capability...",
                            parameters: {
                                type: "object",
                                properties: {
                                    userInput: {
                                        type: "string",
                                        description: "the user input"
                                    }
                                },
                                required: ["userInput"]
                            }
                        }
                    ]
                }
            };

            // Send session update
            try {
                socket.send(JSON.stringify(sessionConfig));
            } catch (e) {
                console.error("Error sending session update:", e);
            }

            // Send each item in history
            conversationHistory.forEach((msg) => {
                const messageConfig = {
                    type: "conversation.item.create",
                    item: {
                        type: "message",
                        role: msg.role,
                        content: [
                            {
                                type: msg.role === "user" ? "input_text" : "text",
                                text: msg.content
                            }
                        ]
                    }
                };

                try {
                    if (msg.role === "user") {
                        console.log("Sending message:", JSON.stringify(messageConfig));
                        socket.send(JSON.stringify(messageConfig));
                    }
                } catch (e) {
                    console.error("Error sending message:", e);
                }
            });
        }

        async function handleReceivedMessage(data) {
            let activeCharacterLogId = await getFromChromeStorage("digitalHumanLogId");
            let realtimeChatHistory = await getFromChromeStorage("realtimeChatHistory");
            realtimeChatHistory = JSON.parse(realtimeChatHistory);

            switch (data.type) {
                // Session created, send configuration
                case "session.created":
                    console.log("Session created, sending session update.");
                    await sendSessionUpdate();
                    break;

                // Session established after configuration
                case "session.updated":
                    console.log("Session updated. Ready to receive audio.");
                    startRecording();
                    break;

                // User starts speaking
                case "input_audio_buffer.speech_started":
                    console.log("Speech started detected by server.");
                    stopCurrentAudioPlayback();
                    audioQueue = [];
                    isPlaying = false;
                    playVideo = false;
                    break;

                // User stops speaking
                case "input_audio_buffer.speech_stopped":
                    console.log("Speech stopped detected by server.");
                    break;

                // Full transcription of user speech
                case "conversation.item.input_audio_transcription.completed":
                    console.log("Received transcription: " + data.transcript);
                    const userMessageContainer = document.createElement('div');
                    userMessageContainer.classList.add('character-chat-item', 'item-user');

                    const userMessage = document.createElement('span');
                    userMessage.textContent = data.transcript;
                    userMessageContainer.appendChild(userMessage);

                    const chatContent = document.querySelector('.ah-character-chat');
                    chatContent.appendChild(userMessageContainer);
                    chatContent.scrollTop = chatContent.scrollHeight;

                    await appendRealtimeChatHistory("user", data.transcript);
                    break;

                // Response text stream
                case "response.audio_transcript.delta":
                    playVideo = true;
                    const transcript = data.delta;
                    const responseId = data.response_id;

                    if (!markdownBuffer.has(responseId)) {
                        markdownBuffer.set(responseId, "");
                    }

                    const existingBuffer = markdownBuffer.get(responseId);
                    markdownBuffer.set(responseId, existingBuffer + transcript);

                    let aiMessageSpan = responseSpans.get(responseId);

                    if (!aiMessageSpan) {
                        const aiMessageContainer = document.createElement('div');
                        aiMessageContainer.classList.add('character-chat-item', 'item-character');

                        aiMessageSpan = document.createElement('span');
                        aiMessageSpan.classList.add('markdown-content');
                        aiMessageContainer.appendChild(aiMessageSpan);

                        const chatContainer = document.querySelector('.ah-character-chat');
                        chatContainer.appendChild(aiMessageContainer);

                        responseSpans.set(responseId, aiMessageSpan);
                    }

                    const fullContent = markdownBuffer.get(responseId);
                    const parsedContent = marked.parse(fullContent);
                    aiMessageSpan.innerHTML = parsedContent;
                    Prism.highlightAllUnder(aiMessageSpan);

                    const chatContainer = document.querySelector('.ah-character-chat');
                    chatContainer.scrollTop = chatContainer.scrollHeight;
                    break;

                // Response audio stream
                case "response.audio.delta":
                    if (data.delta) {
                        // Handle audio delta
                    }
                    break;

                // Full assistant transcription
                case "response.audio_transcript.done":
                    console.log("Received transcription: " + data.transcript);
                    await appendRealtimeChatHistory("assistant", data.transcript);
                    break;

                // Response completed
                case "response.audio.done":
                    console.log("Audio response complete.");
                    isPlaying = false;
                    playVideo = false;
                    break;

                // Function call response
                case "response.function_call_arguments.done":
                    console.log("data：" + data)
                    handleFunctionCall(data);
                    break;
                
                case "session.gpu_full":
                    this.$message.error("The gpu resources are full. Please try again later!")
                    break;

                case "session.insufficient_balance":
                    this.$message.error("Insufficient balance, service has stopped, please recharge!")
                    break;
          
                default:
                    console.warn("Unhandled event type: " + data.type);
            }
        }

        function handleFunctionCall(eventJson) {
            try {
                const arguments = eventJson.arguments;
                const functionCallArgs = JSON.parse(arguments);
                const userInput = functionCallArgs.userInput;
                const callId = eventJson.call_id;

                if (userInput) {
                    // Call handleWithMemAgent to process user input
                    handleWithMemAgent(userInput)
                        .then(result => {
                            // Print the response from backend
                            console.log("Result from backend: " + result);
                            // Send the result back to the caller
                            sendFunctionCallResult(result, callId);
                        })
                        .catch(error => {
                            console.error("Error calling MemAgent:", error);
                        });
                } else {
                    console.log("City not provided for get_weather function.");
                }
            } catch (error) {
                console.error("Error parsing function call arguments: ", error);
            }
        }

        function handleWithMemAgent(userInput) {
            return new Promise(async (resolve, reject) => {
                let chatId = await getFromChromeStorage("chatId");
                // Send request to Java backend API
                fetch('https://'+baseUrl + '/api/realtime_function_call', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        userInput: userInput,  // Pass user input to backend
                        license: license,
                        chatId: chatId
                    }),
                })
                    .then(response => response.text())  // Parse response content
                    .then(result => {
                        // Handle the returned result
                        resolve(result);  // Return result to caller
                    })
                    .catch(error => {
                        console.error("Error during function call:", error);
                        reject(error);  // Handle error
                    });
            });
        }

        function sendFunctionCallResult(result, callId) {
            const resultJson = {
                type: "conversation.item.create",
                item: {
                    type: "function_call_output",
                    output: result,
                    call_id: callId
                }
            };

            socket.send(JSON.stringify(resultJson));
            console.log("Sent function call result: ", resultJson);

            // Actively request a response.create to get the result
            const rpJson = {
                type: "response.create"
            };
            socket.send(JSON.stringify(rpJson));
            console.log("Response sent: ", rpJson);
        }

        function stopCurrentAudioPlayback() {
            if (currentAudioSource) {
                currentAudioSource.stop();
                currentAudioSource = null;
                console.log("Current audio playback stopped.");
            }
        }

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                    audioStream = stream;
                    const source = audioContext.createMediaStreamSource(stream);
                    // Increase buffer size to 8192
                    audioProcessor = audioContext.createScriptProcessor(8192, 1, 1);

                    audioProcessor.onaudioprocess = (event) => {
                        if (socket && socket.readyState === WebSocket.OPEN) {
                            const inputBuffer = event.inputBuffer.getChannelData(0);
                            const pcmData = floatTo16BitPCM(inputBuffer);
                            const base64PCM = base64EncodeAudio(new Uint8Array(pcmData));

                            // Increase audio chunk size to 4096
                            const chunkSize = 4096;
                            for (let i = 0; i < base64PCM.length; i += chunkSize) {
                                const chunk = base64PCM.slice(i, i + chunkSize);
                                socket.send(JSON.stringify({ type: "input_audio_buffer.append", audio: chunk }));
                            }
                        }
                    };

                    source.connect(audioProcessor);
                    audioProcessor.connect(audioContext.destination);
                    console.log("Recording started");
                })
                .catch(error => {
                    console.error("Unable to access microphone: ", error);
                });
        }

        function floatTo16BitPCM(float32Array) {
            const buffer = new ArrayBuffer(float32Array.length * 2);
            const view = new DataView(buffer);
            let offset = 0;
            for (let i = 0; i < float32Array.length; i++, offset += 2) {
                let s = Math.max(-1, Math.min(1, float32Array[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
            }
            return buffer;
        }

        function base64EncodeAudio(uint8Array) {
            let binary = '';
            const chunkSize = 0x8000; // Keep 32KB chunk size
            for (let i = 0; i < uint8Array.length; i += chunkSize) {
                const chunk = uint8Array.subarray(i, i + chunkSize);
                binary += String.fromCharCode.apply(null, chunk);
            }
            return btoa(binary);
        }



        function stopRecording() {
            if (audioProcessor) {
                audioProcessor.disconnect();
            }
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
            }
            if (socket) {
                socket.close();
            }
        }


        // Play the next audio segment and synchronize lip movement
        function playNextAudio() {
            if (audioQueue.length > 0) {
                isPlaying = true;
                const audioData = audioQueue.shift(); // Get one audio segment from the queue
                playPCM(audioData, playNextAudio); // Play the audio
            } else {
                isPlaying = false;
            }
        }

        function playPCM(pcmBuffer, callback) {
            const wavBuffer = createWavBuffer(pcmBuffer, 24000);
            audioContext.decodeAudioData(wavBuffer, function (audioBuffer) {
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.onended = callback; // Call callback after audio playback ends
                source.start(0);
                currentAudioSource = source;
                console.log("Audio played successfully.");
            }, function (error) {
                console.error("Error decoding audio data", error);
                callback(); // Continue to play the next audio if decoding fails
            });
        }

        function createWavBuffer(pcmBuffer, sampleRate) {
            const wavHeader = new ArrayBuffer(44);
            const view = new DataView(wavHeader);

            // RIFF header
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + pcmBuffer.byteLength, true); // Chunk size
            writeString(view, 8, 'WAVE');

            // fmt subchunk
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true); // Subchunk1 size (16 for PCM)
            view.setUint16(20, 1, true);  // Audio format (1 for PCM)
            view.setUint16(22, 1, true);  // Number of channels (1 for mono)
            view.setUint32(24, sampleRate, true); // Sample rate
            view.setUint32(28, sampleRate * 2, true); // Byte rate (Sample Rate * Block Align)
            view.setUint16(32, 2, true);  // Block align (Channels * Bits per sample / 8)
            view.setUint16(34, 16, true); // Bits per sample

            // data subchunk
            writeString(view, 36, 'data');
            view.setUint32(40, pcmBuffer.byteLength, true); // Subchunk2 size

            function writeString(view, offset, string) {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            }

            return concatenateBuffers(wavHeader, pcmBuffer);
        }

        function concatenateBuffers(buffer1, buffer2) {
            const tmp = new Uint8Array(buffer1.byteLength + buffer2.byteLength);
            tmp.set(new Uint8Array(buffer1), 0);
            tmp.set(new Uint8Array(buffer2), buffer1.byteLength);
            return tmp.buffer;
        }

       

        async function appendRealtimeChatHistory(role, content) {
            let history = localStorage.getItem("realtimeChatHistory");
            let realtimeChatHistory = history ? JSON.parse(history) : [];

            realtimeChatHistory.push({ role, content });

            localStorage.setItem("realtimeChatHistory", JSON.stringify(realtimeChatHistory));
        }
        
    }

    async function initDigtalHumanHistoryData(){

      let realtimeChatHistory = [];

      const historyStr = localStorage.getItem("realtimeChatHistory");
      realtimeChatHistory = historyStr ? JSON.parse(historyStr) : [];

      // 进入页面，渲染历史对话记录
      if (realtimeChatHistory && realtimeChatHistory.length > 0) {
        realtimeChatHistory.forEach(item => {
          appendContentToList(item.role, item.content);
        })
        document.querySelector('.scroller').scrollTop = document.querySelector('.scroller').scrollHeight;
      }
    }

    function appendContentToList(role, context) {
      const container = document.createElement('div');
      container.classList.add('item', role === 'user' ? 'item-right' : 'item-left');

      const contentDiv = document.createElement('div');
      contentDiv.classList.add('item-content');
      const contentSpan = document.createElement('span');
      contentSpan.textContent = context; // Display transcribed user input text
      contentDiv.appendChild(contentSpan);
      container.appendChild(contentDiv);

      // Add the user message to the chat box
      const chatContent = document.querySelector('.scroller');
      chatContent.appendChild(container);
      return contentSpan;
    }

    
    initDigtalHumanHistoryData();

    initDigtalHumanRealtimeButton();

</script>

</html>